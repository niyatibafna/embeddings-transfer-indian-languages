{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "educated-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import morfessor\n",
    "import fasttext\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "computational-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "morfessor = morfessor.MorfessorIO()\n",
    "mr_segment = morfessor.read_binary_model_file('marathi_data/mr.morfessor')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "asian-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Get Hindi embeddings\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.asarray(list(map(float, tokens[1:])))\n",
    "    return data\n",
    "\n",
    "\n",
    "# hin_embeddings = fasttext.load_model(\"hin_embeddings/hin.embeddings.300.bin\")\n",
    "hin_embeddings = fasttext.load_model(\"hin_embeddings/cc.hi.300.bin\")\n",
    "# hin_embeddings = load_vectors(\"hin_embeddings/wiki.hi.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "express-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Marathi embeddings for testing direct approaches\n",
    "\n",
    "# mr_embeddings = load_vectors(\"mr_embeddings/mr.crosslingual.100.vec\")\n",
    "mr_embeddings = load_vectors(\"mr_embeddings/mr.crosslingual3.300.vec\")\n",
    "# mr_embeddings = load_vectors(\"mr_embeddings/mr.crosslingual.300.vec\")\n",
    "# mr_embeddings = load_vectors(\"mr_embeddings/mr.crosslingual2.300.vec\")\n",
    "# mr_embeddings_backup = fasttext.load_model(\"mr_embeddings/hi_mr.embeddings.300.bin\")\n",
    "# mr_embeddings_backup = fasttext.load_model(\"hin_embeddings/hin.embeddings.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "naval-quest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "mr_embeddings = fasttext.load_model('mr_embeddings/cc.mr.300.bin')\n",
    "# mr_embeddings = load_vectors(\"mr_embeddings/mr.cc.crosslingual.300.vec\")\n",
    "# mr_embeddings = fasttext.load_model(\"mr_embeddings/hi_mr.embeddings.300.bin\")\n",
    "# mr_embeddings = fasttext.load_model(\"mr_embeddings/mr.embeddings.300.bin\")\n",
    "# mr_embeddings = fasttext.load_model(\"mr_embeddings/mr.embeddings.unsegmented.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "following-indie",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "mr_embeddings_backup = fasttext.load_model(\"mr_embeddings/mr.embeddings.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pleased-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment mr words using morfessor\n",
    "def get_segments(word):\n",
    "    return mr_segment.viterbi_segment(word)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "laden-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map morphs to Hindi morphs \n",
    "def get_h_map_self(morph_l):\n",
    "    return morph_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "injured-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map morphs to Hindi morphs : baseline ned\n",
    "\n",
    "with open(\"morph_mappings/baseline_ned.json\", \"r\") as f:\n",
    "    morph_mapping_str = json.load(f)\n",
    "    morph_mapping = {int(k):v for k,v in morph_mapping_str.items()}\n",
    "    f.close()\n",
    "\n",
    "# with open(\"morph_mappings/baseline_ned_tag.json\", \"r\") as f:\n",
    "#     morph_mapping_str = json.load(f)\n",
    "#     morph_mapping_tag = {int(k):v for k,v in morph_mapping_str.items()}\n",
    "#     f.close()\n",
    "\n",
    "\n",
    "    \n",
    "with open(\"tag_distributions/tag_dist_l.json\", \"r\") as l_file:\n",
    "    tag_dist_l = json.load(l_file)\n",
    "    \n",
    "with open(\"tag_distributions/tag_dist_h.json\", \"r\") as h_file:\n",
    "    tag_dist_h = json.load(h_file)\n",
    "    \n",
    "morph_voc_l = list(tag_dist_l.keys())\n",
    "morph_voc_h = list(tag_dist_h.keys())\n",
    "\n",
    "def get_h_map_ned(morph_l):\n",
    "    try:\n",
    "        return morph_voc_h[morph_mapping[morph_voc_l.index(morph_l)]]\n",
    "    except ValueError:\n",
    "        print(\"error\")\n",
    "        return morph_l\n",
    "\n",
    "def get_h_map_ned_tag(morph_l):\n",
    "    try:\n",
    "        return morph_voc_h[morph_mapping_tag[morph_voc_l.index(morph_l)]]\n",
    "    except ValueError:\n",
    "        print(\"error\")\n",
    "        return morph_l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "swiss-shoulder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 4708), (1, 2108), (2, 7600), (3, 524), (4, 27751)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(morph_mapping.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "exempt-intervention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'राव'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_h_map_ned(\"गाव\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "convinced-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hindi embedding for list of Marathi morphs\n",
    "def get_h_embedding(word_l):\n",
    "    morph_list_l = get_segments(word_l)\n",
    "    morph_list_h = [get_h_map_self(morph) for morph in morph_list_l]\n",
    "    word_embedding = np.asarray([hin_embeddings[morph] for morph in morph_list_h])\n",
    "    return np.sum(word_embedding, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "adaptive-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get marathi embedding for list of Marathi morphs\n",
    "def get_l_embedding(word_l, backup=False):\n",
    "    try:\n",
    "        return mr_embeddings[word_l], backup\n",
    "    except KeyError:\n",
    "        morph_list_l = get_segments(word_l)\n",
    "        embedding_list = list()\n",
    "        for m_l in morph_list_l: \n",
    "            try:\n",
    "                embedding_list.append(mr_embeddings[m_l])\n",
    "            except KeyError:\n",
    "                embedding_list.append(mr_embeddings_backup[m_l])\n",
    "    #             backup = True\n",
    "    #             break\n",
    "                break\n",
    "        if backup:\n",
    "            embedding_list = [mr_embeddings_backup[m_l] for m_l in morph_list_l[:1]]\n",
    "        word_embedding = np.asarray(embedding_list)\n",
    "        return np.sum(word_embedding, axis=0), backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "generous-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model judgment for one word pair\n",
    "def get_model_judgment(word_pair):\n",
    "    (word1, word2) = word_pair\n",
    "    e1, backup = get_l_embedding(word1)\n",
    "    e2, backup = get_l_embedding(word2, backup)\n",
    "    if e1 is None or e2 is None:\n",
    "        return None\n",
    "    cos_sim = 1 - distance.cosine(e1,e2)\n",
    "#     cos_sim = 1 - distance.cosine(get_h_embedding(word1), get_h_embedding(word2))\n",
    "    return cos_sim\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "involved-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get m j for all pairs\n",
    "def get_model_judgments(word_pairs):\n",
    "    judgments = [get_model_judgment(word_pair) for word_pair in word_pairs]\n",
    "    return judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "functioning-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word sim dataset\n",
    "# Process word sim dataset\n",
    "def get_word_sim_dataset(path):\n",
    "    word_sim = open(path, \"r\").read().split(\"\\n\")\n",
    "    word_pairs = [(pair.split(\"\\t\")[0], pair.split(\"\\t\")[1]) for pair in word_sim]\n",
    "    judgments = [float(pair.split(\"\\t\")[2]) for pair in word_sim]\n",
    "    return word_pairs, judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "olympic-performance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.5489330335743691, pvalue=1.6062365044424024e-09)\n"
     ]
    }
   ],
   "source": [
    "# Hindi embeddings on Marathi word sim\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "precise-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.3994444165362607, pvalue=2.6625810172676956e-05)\n"
     ]
    }
   ],
   "source": [
    "# Hindi embeddings on Marathi word sim\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "graduate-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.4876080751868102, pvalue=1.5227681833473377e-07)\n"
     ]
    }
   ],
   "source": [
    "#CROSSLINGUAL 500000 Hindi sentences\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "tight-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.4362318992097995, pvalue=3.674277345653242e-06)\n"
     ]
    }
   ],
   "source": [
    "#SELF fastext 300\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sunset-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.4760644906469756, pvalue=3.259849667020419e-07)\n"
     ]
    }
   ],
   "source": [
    "#SELF fastext 100\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "suspected-trigger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.4272678268388106, pvalue=6.083299566974009e-06)\n"
     ]
    }
   ],
   "source": [
    "#SELF Hindi cc 300\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "australian-commissioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.39474028542336564, pvalue=3.3742445552604146e-05)\n"
     ]
    }
   ],
   "source": [
    "# BASELINE NED fasttext 100\n",
    "\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "miniature-myrtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.4185873937726948, pvalue=9.779397990726483e-06)\n"
     ]
    }
   ],
   "source": [
    "# BASELINE NED cc 300\n",
    "\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fabulous-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "SpearmanrResult(correlation=0.3936806517938399, pvalue=3.5574243600696806e-05)\n"
     ]
    }
   ],
   "source": [
    "# BASELINE NED Hindi 300\n",
    "\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "mysterious-polymer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "SpearmanrResult(correlation=0.36379149108221437, pvalue=0.0001470211585492415)\n"
     ]
    }
   ],
   "source": [
    "# BASELINE NED TAG cc 300\n",
    "\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "foster-greek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "SpearmanrResult(correlation=0.411683720125784, pvalue=1.4133900483873763e-05)\n"
     ]
    }
   ],
   "source": [
    "# BASELINE NED TAG Hindi 300\n",
    "\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "altered-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF hin wiki 300\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abandoned-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.4921998209147555, pvalue=1.1161682576661716e-07)\n"
     ]
    }
   ],
   "source": [
    "# CROSSLINGUAL Hindi segmented with 300 fasttext (trained from segmented data), as backup Marathi\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "defensive-singing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.5223833243012493, pvalue=1.2878400849307844e-08)\n"
     ]
    }
   ],
   "source": [
    "# Downloaded 300 fasttext Marathi\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "pursuant-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.45898726381961713, pvalue=9.561449920225694e-07)\n"
     ]
    }
   ],
   "source": [
    "# Marathi 300 fasttext (trained on segmented data)\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "level-essex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.39192529911462526, pvalue=3.881478379336467e-05)\n"
     ]
    }
   ],
   "source": [
    "# Marathi 100 fasttext (trained on segmented data)\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "assisted-silly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "SpearmanrResult(correlation=0.44282517512684916, pvalue=2.5124182999621907e-06)\n"
     ]
    }
   ],
   "source": [
    "#Marathi CROSSLINGUAL 300, using cc 300 Hindi pretrained, 50k Marathi segmented to train - backup 300 fasttext marathi\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "human_judgments = [human_judgments[idx] for idx in range(len(human_judgments)) if model_judgments[idx] is not None]\n",
    "model_judgments = list(filter(lambda x: x is not None, model_judgments))\n",
    "print(len(human_judgments))\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "informal-tactics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.48868002988329123, pvalue=1.6486611801230756e-15)\n"
     ]
    }
   ],
   "source": [
    "#Marathi JOINT 300, using segmented Hindi and Mar\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/hin.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "swiss-organizer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "SpearmanrResult(correlation=0.49047116725731515, pvalue=1.2553038614035856e-07)\n"
     ]
    }
   ],
   "source": [
    "# CROSSLINGUAL Hindi segmented with 300 fasttext (trained from segmented data), as backup Marathi\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "human_judgments = [human_judgments[idx] for idx in range(len(human_judgments)) if model_judgments[idx] is not None]\n",
    "model_judgments = list(filter(lambda x: x is not None, model_judgments))\n",
    "print(len(human_judgments))\n",
    "\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "infinite-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कळफलक\n",
      "['कळ', 'फलक']\n",
      "टेलिफोन\n",
      "['टेलि', 'फोन']\n",
      "दूरदर्शन\n",
      "['दूर', 'दर्शन']\n",
      "बटाटा\n",
      "['बटाट', 'ा']\n",
      "अंडी\n",
      "['अ', 'ंडी']\n",
      "कोबी\n",
      "['को', 'बी']\n",
      "यासिर\n",
      "['यास', 'िर']\n",
      "शांतता\n",
      "['शांत', 'ता']\n",
      "अराफात\n",
      "['अ', 'राफा', 'त']\n",
      "दहशतवादी\n",
      "['दहशतवाद', 'ी']\n",
      "अराफात\n",
      "['अ', 'राफा', 'त']\n",
      "पॉपकॉर्न\n",
      "['पॉप', 'कॉर्', 'न']\n",
      "भौतिकशास्त्र\n",
      "['भौतिक', 'शास्त्र']\n",
      "प्रोटॉन\n",
      "['प्रो', 'ट', 'ॉन']\n",
      "रसायनशास्त्र\n",
      "['रसायन', 'शास्त्र']\n",
      "भौतिकशास्त्र\n",
      "['भौतिक', 'शास्त्र']\n",
      "रसायनशास्त्र\n",
      "['रसायन', 'शास्त्र']\n",
      "रत्नजडित\n",
      "['रत्न', 'जड', 'ित']\n",
      "शेगडी\n",
      "['शे', 'गडी']\n",
      "कोंबडा\n",
      "['कोंब', 'डा']\n",
      "कोंबडा\n",
      "['कोंब', 'डा']\n",
      "स्मशानभूमी\n",
      "['स्मशान', 'भूमी']\n",
      "काच\n",
      "['का', 'च']\n",
      "जादूगार\n",
      "['जादू', 'गार']\n",
      "प्राणीसंग्रहालय\n",
      "['प्राणी', 'संग्रहालय']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मनोदोषचिकित्सा\n",
      "['मनो', 'दोष', 'चिकित्सा']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "मानसशास्त्र\n",
      "['मानस', 'शास्त्र']\n",
      "आकाशगंगा\n",
      "['आकाश', 'गंगा']\n",
      "खगोलशास्त्रज्ञ\n",
      "['खगोल', 'शास्त्रज्ञ']\n",
      "ऑब्जेक्ट\n",
      "['ऑब्जेक', '्ट']\n",
      "जग्वार\n",
      "['जग', '्', 'वार']\n",
      "जग्वार\n",
      "['जग', '्', 'वार']\n",
      "प्रयोगशाळा\n",
      "['प्रयोग', 'शाळा']\n",
      "प्रयोगशाळा\n",
      "['प्रयोग', 'शाळा']\n",
      "लँडस्केप\n",
      "['लँड', 'स्केप']\n",
      "सैन्याने\n",
      "['सैन्य', 'ाने']\n",
      "जपानी\n",
      "['जपान', 'ी']\n",
      "104\n",
      "SpearmanrResult(correlation=0.500623367855118, pvalue=6.238077453623574e-08)\n"
     ]
    }
   ],
   "source": [
    "# CROSSLINGUAL Hindi segmented with 300 fasttext (trained from segmented data), as backup Marathi\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "human_judgments = [human_judgments[idx] for idx in range(len(human_judgments)) if model_judgments[idx] is not None]\n",
    "model_judgments = list(filter(lambda x: x is not None, model_judgments))\n",
    "print(len(human_judgments))\n",
    "\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "animal-samoa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "104\n",
      "SpearmanrResult(correlation=0.500965877522097, pvalue=6.090206269207641e-08)\n"
     ]
    }
   ],
   "source": [
    "# CROSSLINGUAL Hindi segmented with 300 fasttext (trained from segmented data) with 2 million sentences, as backup Marathi\n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "# human_judgments = [human_judgments[idx] for idx in range(len(human_judgments)) if model_judgments[idx] is not None]\n",
    "# model_judgments = list(filter(lambda x: x is not None, model_judgments))\n",
    "print(len(human_judgments))\n",
    "print(len(model_judgments))\n",
    "\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "involved-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "104\n",
      "SpearmanrResult(correlation=0.3547685501762518, pvalue=0.00021974351085621348)\n"
     ]
    }
   ],
   "source": [
    "# CROSSLINGUAL Hindi segmented with 300 fasttext (trained from segmented data), JOINT as backup \n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "# human_judgments = [human_judgments[idx] for idx in range(len(human_judgments)) if model_judgments[idx] is not None]\n",
    "# model_judgments = list(filter(lambda x: x is not None, model_judgments))\n",
    "print(len(human_judgments))\n",
    "print(len(model_judgments))\n",
    "\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "relative-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "104\n",
      "SpearmanrResult(correlation=0.24638087391975202, pvalue=0.011694614084061028)\n"
     ]
    }
   ],
   "source": [
    "# CROSSLINGUAL Hindi segmented with 300 fasttext (trained from segmented data), JOINT as backup \n",
    "word_pairs, human_judgments = get_word_sim_dataset(\"evaluation/mr.word_sim.txt\")\n",
    "model_judgments = get_model_judgments(word_pairs)\n",
    "# human_judgments = [human_judgments[idx] for idx in range(len(human_judgments)) if model_judgments[idx] is not None]\n",
    "# model_judgments = list(filter(lambda x: x is not None, model_judgments))\n",
    "print(len(human_judgments))\n",
    "print(len(model_judgments))\n",
    "\n",
    "spearman_correlation = stats.spearmanr(model_judgments, human_judgments)\n",
    "print(spearman_correlation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "minus-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in word_pairs:\n",
    "#     print(p[0], p[1])\n",
    "#     print(get_h_map_ned(p[0]), get_h_map_ned(p[1]))\n",
    "#     print(get_h_map_ned_tag(p[0]), get_h_map_ned_tag(p[1]))\n",
    "#     print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "acoustic-declaration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mr_embeddings[\"मांजर\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-furniture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
