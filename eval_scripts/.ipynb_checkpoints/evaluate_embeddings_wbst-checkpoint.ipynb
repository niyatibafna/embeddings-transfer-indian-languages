{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "educated-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import morfessor\n",
    "import fasttext\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "import json\n",
    "import io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "computational-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Morfessor model\n",
    "\n",
    "morfessor = morfessor.MorfessorIO()\n",
    "mr_segment = morfessor.read_binary_model_file('../data/konkani_data/kon.morfessor')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "asian-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectors\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.asarray(list(map(float, tokens[1:])))\n",
    "    return data\n",
    "\n",
    "\n",
    "# hin_embeddings = fasttext.load_model(\"hin_embeddings/hin.embeddings.300.bin\")\n",
    "# hin_embeddings = fasttext.load_model(\"hin_embeddings/cc.hi.300.bin\")\n",
    "# hin_embeddings = load_vectors(\"hin_embeddings/wiki.hi.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "express-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Get Marathi embeddings for testing direct approaches\n",
    "\n",
    "\n",
    "unseg = fasttext.load_model(\"mr_embeddings/mr.embeddings.unsegmented.300.bin\")\n",
    "seg = fasttext.load_model(\"mr_embeddings/mr.embeddings.300.bin\")\n",
    "iter1 = load_vectors(\"mr_embeddings/mr.crosslingual.300.vec\")\n",
    "pret = fasttext.load_model('mr_embeddings/cc.mr.300.bin')\n",
    "\n",
    "\n",
    "\n",
    "# iter2 = load_vectors(\"mr_embeddings/mr.crosslingual2.300.vec\")\n",
    "\n",
    "\n",
    "# mr_embeddings = load_vectors(\"mr_embeddings/mr.crosslingual.100.vec\")\n",
    "\n",
    "# mr_embeddings_backup = fasttext.load_model(\"mr_embeddings/hi_mr.embeddings.300.bin\")\n",
    "# mr_embeddings_backup = fasttext.load_model(\"mr_embeddings/hi_mr.embeddings.300.bin\")\n",
    "# mr_embeddings_backup = fasttext.load_model(\"hin_embeddings/hin.embeddings.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_embeddings_backup = fasttext.load_model(\"nep_embeddings/nep.embeddings.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "arctic-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mr_embeddings = load_vectors(\"nep_embeddings/nep.embeddings.crosslingual.300.vec\")\n",
    "# mr_embeddings = fasttext.load_model(\"nep_embeddings/nep.embeddings.unsegmented.300.bin\")\n",
    "# mr_embeddings = fasttext.load_model(\"nep_embeddings/cc.ne.300.bin\")\n",
    "# mr_embeddings = fasttext.load_model(\"nep_embeddings/nep.embeddings.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "naval-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mr_embeddings = load_vectors(\"mr_embeddings/mr.cc.crosslingual.300.vec\")\n",
    "# mr_embeddings = fasttext.load_model(\"mr_embeddings/hi_mr.embeddings.300.bin\")\n",
    "\n",
    "# mr_embeddings = fasttext.load_model(\"mr_embeddings/mr.embeddings.100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "following-indie",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "pleased-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment mr words using morfessor\n",
    "def get_segments(word):\n",
    "    return mr_segment.viterbi_segment(word)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adaptive-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get marathi embedding for list of Marathi morphs\n",
    "def get_l_embedding(word_l, backup=False):\n",
    "#     try:\n",
    "#         return mr_embeddings[word_l], backup\n",
    "#     except KeyError:\n",
    "    morph_list_l = get_segments(word_l)\n",
    "    embedding_list = list()\n",
    "    for m_l in morph_list_l: \n",
    "        try:\n",
    "            embedding_list.append(mr_embeddings[m_l])\n",
    "        except KeyError:\n",
    "            embedding_list.append(mr_embeddings_backup[m_l])\n",
    "            backup = True\n",
    "#             break\n",
    "    if backup:\n",
    "        embedding_list = [mr_embeddings_backup[m_l] for m_l in morph_list_l]\n",
    "    word_embedding = np.asarray(embedding_list)\n",
    "    return np.sum(word_embedding, axis=0), backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "generous-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model judgment for one word pair\n",
    "def get_model_cosim(word_pair):\n",
    "    (word1, word2) = word_pair\n",
    "#     print(word1)\n",
    "    e1, backup = get_l_embedding(word1)\n",
    "#     print(word2)\n",
    "    e2, backup = get_l_embedding(word2, backup)\n",
    "    cos_sim = 1 - distance.cosine(e1,e2)\n",
    "#     cos_sim = 1 - distance.cosine(get_h_embedding(word1), get_h_embedding(word2))\n",
    "    return cos_sim\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "earned-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_judgment(question, option_set):\n",
    "    all_cosims = list()\n",
    "    for opt in option_set:\n",
    "        all_cosims.append(get_model_cosim((question, opt)))\n",
    "        \n",
    "    return option_set[np.argmax(all_cosims)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "involved-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get m j for all pairs\n",
    "def get_model_judgments(questions, options):\n",
    "#     print(len(questions))\n",
    "#     print(len(options))\n",
    "    judgments = [get_model_judgment(question, option_set) for question, option_set in list(zip(questions, options))]\n",
    "    return judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "functioning-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_wbst_dataset(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        wbst = json.load(f)\n",
    "        \n",
    "    questions = list()\n",
    "    answers = list()\n",
    "    options = list()\n",
    "    for q in wbst:\n",
    "        questions.append(q)\n",
    "        answers.append(wbst[q][\"answer\"])\n",
    "        opt = wbst[q][\"detractors\"] + [wbst[q][\"answer\"]]\n",
    "        random.shuffle(opt)\n",
    "        options.append(opt)\n",
    "    return questions, answers, options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "moderate-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "65.27581329561528\n",
      "1\n",
      "69.16548797736917\n",
      "2\n",
      "69.71252566735113\n",
      "3\n",
      "70.73921971252567\n",
      "4\n",
      "71.61862527716187\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Nepali embeddings\n",
    "# test_results = dict()\n",
    "# emb_type = \"baseline\"\n",
    "# emb_type = \"segm\"\n",
    "emb_type = \"iter\"\n",
    "# emb_type = \"pret\"\n",
    "\n",
    "\n",
    "parameters = [(10, 6), (10, 5), (20, 6), (20, 5), (50, 5)]\n",
    "for pidx, (MIN_FREQ, N) in enumerate(parameters):\n",
    "    print(pidx)\n",
    "    \n",
    "    questions, answers, options = get_wbst_dataset(\"evaluation/nep_wbst/nep.wbst-{}-{}.json\".format(MIN_FREQ, N))\n",
    "    \n",
    "    \n",
    "    model_judgments = get_model_judgments(questions, options)\n",
    "    accuracy = 0\n",
    "    for idx, ans in enumerate(answers):\n",
    "        if model_judgments[idx]==ans:\n",
    "            accuracy+=1\n",
    "    print(accuracy*100/len(answers))\n",
    "    \n",
    "    if pidx not in test_results:\n",
    "        test_results[pidx] = dict()\n",
    "        test_results[pidx][\"parameters\"] = (MIN_FREQ, N)\n",
    "        test_results[pidx][\"size\"] = len(questions)\n",
    "    test_results[pidx][emb_type] = accuracy*100/len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "protecting-element",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'parameters': (10, 6),\n",
       "  'size': 1414,\n",
       "  'baseline': 58.2036775106082,\n",
       "  'iter': 65.27581329561528,\n",
       "  'pret': 74.11598302687412,\n",
       "  'segm': 63.932107496463935},\n",
       " 1: {'parameters': (10, 5),\n",
       "  'size': 1414,\n",
       "  'baseline': 61.1032531824611,\n",
       "  'iter': 69.16548797736917,\n",
       "  'pret': 76.37906647807638,\n",
       "  'segm': 67.75106082036775},\n",
       " 2: {'parameters': (20, 6),\n",
       "  'size': 974,\n",
       "  'baseline': 62.32032854209446,\n",
       "  'iter': 69.71252566735113,\n",
       "  'pret': 76.38603696098562,\n",
       "  'segm': 69.30184804928132},\n",
       " 3: {'parameters': (20, 5),\n",
       "  'size': 974,\n",
       "  'baseline': 63.860369609856264,\n",
       "  'iter': 70.73921971252567,\n",
       "  'pret': 78.2340862422998,\n",
       "  'segm': 69.50718685831622},\n",
       " 4: {'parameters': (50, 5),\n",
       "  'size': 451,\n",
       "  'baseline': 66.29711751662971,\n",
       "  'iter': 71.61862527716187,\n",
       "  'pret': 77.16186252771618,\n",
       "  'segm': 70.28824833702882}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "living-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>size</th>\n",
       "      <th>baseline</th>\n",
       "      <th>segm</th>\n",
       "      <th>iter</th>\n",
       "      <th>pret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(10, 6)</td>\n",
       "      <td>1414</td>\n",
       "      <td>58.203678</td>\n",
       "      <td>63.932107</td>\n",
       "      <td>65.275813</td>\n",
       "      <td>74.115983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(10, 5)</td>\n",
       "      <td>1414</td>\n",
       "      <td>61.103253</td>\n",
       "      <td>67.751061</td>\n",
       "      <td>69.165488</td>\n",
       "      <td>76.379066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(20, 6)</td>\n",
       "      <td>974</td>\n",
       "      <td>62.320329</td>\n",
       "      <td>69.301848</td>\n",
       "      <td>69.712526</td>\n",
       "      <td>76.386037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>974</td>\n",
       "      <td>63.86037</td>\n",
       "      <td>69.507187</td>\n",
       "      <td>70.73922</td>\n",
       "      <td>78.234086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(50, 5)</td>\n",
       "      <td>451</td>\n",
       "      <td>66.297118</td>\n",
       "      <td>70.288248</td>\n",
       "      <td>71.618625</td>\n",
       "      <td>77.161863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parameters  size   baseline       segm       iter       pret\n",
       "0    (10, 6)  1414  58.203678  63.932107  65.275813  74.115983\n",
       "1    (10, 5)  1414  61.103253  67.751061  69.165488  76.379066\n",
       "2    (20, 6)   974  62.320329  69.301848  69.712526  76.386037\n",
       "3    (20, 5)   974   63.86037  69.507187   70.73922  78.234086\n",
       "4    (50, 5)   451  66.297118  70.288248  71.618625  77.161863"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(test_results).transpose()\n",
    "cols = [\"parameters\", \"size\", \"baseline\", \"segm\", \"iter\", \"pret\"]\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "outstanding-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1414\n",
      "1414\n",
      "69.16548797736917\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual with 300 backup\n",
    "# MIN = 10, N = 4\n",
    "# always segment , take all morphs\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/nep_wbst/nep.wbst-10-5.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "mobile-basin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "60.777683854606934\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual 2M with 300 backup\n",
    "# MIN = 50, N = 4 \n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "different-halifax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "58.918005071851226\n"
     ]
    }
   ],
   "source": [
    "# 300\n",
    "# MIN = 10, N = 4\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "quantitative-requirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "84.69991546914623\n"
     ]
    }
   ],
   "source": [
    "# Pretrained\n",
    "# MIN = 10, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "applied-consciousness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\n",
      "435\n",
      "59.08045977011494\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual with 300 backup\n",
    "# MIN = 10, N = 5 ans freq > 10\n",
    "# always segment , take all morphs\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "alert-toyota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\n",
      "435\n",
      "62.98850574712644\n"
     ]
    }
   ],
   "source": [
    "# 300\n",
    "# MIN = 10, N = 5 ans freq > 10\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dangerous-biography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "58.66441251056636\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual with 300 backup\n",
    "# MIN = 10, N = 5 \n",
    "# always segment , take all morphs\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "interstate-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "54.7759932375317\n"
     ]
    }
   ],
   "source": [
    "# 300\n",
    "# MIN = 10, N = 5\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "surprised-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "84.86897717666949\n"
     ]
    }
   ],
   "source": [
    "# Pretrained\n",
    "# MIN = 10, N = 5\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "stretch-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "293\n",
      "63.13993174061434\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual with 300 backup\n",
    "# MIN = 50, N = 5 \n",
    "# always segment , take all morphs\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "sealed-result",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "293\n",
      "63.822525597269625\n"
     ]
    }
   ],
   "source": [
    "# 300\n",
    "# MIN = 50, N = 5\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fallen-wichita",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "293\n",
      "82.5938566552901\n"
     ]
    }
   ],
   "source": [
    "# Pretrained\n",
    "# MIN = 50, N = 5\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "loaded-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "293\n",
      "67.23549488054607\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual with 300 backup\n",
    "# MIN = 50, N = 4\n",
    "# always segment , take all morphs\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "center-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "293\n",
      "63.13993174061434\n"
     ]
    }
   ],
   "source": [
    "# 300\n",
    "# MIN = 50, N = 4\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "empirical-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "293\n",
      "81.22866894197952\n"
     ]
    }
   ],
   "source": [
    "# Pretrained\n",
    "# MIN = 50, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "detected-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "64.47368421052632\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual with 300 backup\n",
    "# MIN = 20, N = 4\n",
    "# always segment , take all morphs\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "coupled-direction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "59.941520467836256\n"
     ]
    }
   ],
   "source": [
    "# 300\n",
    "# MIN = 20, N = 4\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "parliamentary-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "87.57309941520468\n"
     ]
    }
   ],
   "source": [
    "# Pretrained\n",
    "# MIN = 20, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "infectious-hardwood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "59.941520467836256\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual with 300 backup\n",
    "# MIN = 20, N = 5\n",
    "# always segment , take all morphs\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "headed-agriculture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "53.654970760233915\n"
     ]
    }
   ],
   "source": [
    "# 300\n",
    "# MIN = 20, N = 5\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "eight-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "84.50292397660819\n"
     ]
    }
   ],
   "source": [
    "# Pretrained\n",
    "# MIN = 20, N = 5\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "comprehensive-zoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "48.9766081871345\n"
     ]
    }
   ],
   "source": [
    "# Unsegmented\n",
    "# MIN = 20, N = 5\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "sustained-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "57.89473684210526\n"
     ]
    }
   ],
   "source": [
    "# Unsegmented\n",
    "# MIN = 20, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "recorded-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "51.90194420963652\n"
     ]
    }
   ],
   "source": [
    "# Unsegmented\n",
    "# MIN = 10, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "victorian-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "51.22569737954353\n"
     ]
    }
   ],
   "source": [
    "# Unsegmented\n",
    "# MIN = 10, N = 5\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "cheap-champagne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "293\n",
      "58.02047781569966\n"
     ]
    }
   ],
   "source": [
    "# Unsegmented\n",
    "# MIN = 50, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "pursuant-gallery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "58.187134502923975\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual double data\n",
    "# MIN = 20, N = 5\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "stuck-scoop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "684\n",
      "64.32748538011695\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual double data\n",
    "# MIN = 20, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "functioning-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "61.53846153846154\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual double data\n",
    "# MIN = 10, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "nervous-madonna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "56.29754860524091\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual double data\n",
    "# MIN = 10, N = 5\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "falling-float",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "293\n",
      "68.9419795221843\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual double data\n",
    "# MIN = 50, N = 4\n",
    "# Direct embedding\n",
    "\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-jenny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "alpine-thinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "55.790363482671175\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual double data\n",
    "# MIN = 50, N = 4\n",
    "# Direct embedding\n",
    "import copy\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "mr_embeddings = copy.copy(iter1)\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "elementary-friend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183\n",
      "1183\n",
      "47.08368554522401\n"
     ]
    }
   ],
   "source": [
    "# Crosslingual double data\n",
    "# MIN = 50, N = 4\n",
    "# Direct embedding\n",
    "import copy\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "mr_embeddings = copy.copy(unseg)\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-tennis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-huntington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "complicated-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\n",
      "435\n"
     ]
    }
   ],
   "source": [
    "#SELF Hindi cc 300\n",
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "passing-purpose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.781569965870304\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "southeast-presentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.58703071672355\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "operating-charge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.58703071672355\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "headed-productivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.58703071672355\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "alone-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.493660185967876\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "progressive-killer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.452240067624686\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "later-bacon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.07607776838546\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "artificial-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.69146238377007\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "loose-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.52873563218391\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "stretch-discharge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.241379310344826\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "animated-trial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.75862068965517\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "worldwide-midwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n",
      "811\n",
      "83.23057953144266\n"
     ]
    }
   ],
   "source": [
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "elect-journalist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n",
      "811\n",
      "56.473489519112206\n"
     ]
    }
   ],
   "source": [
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "standing-control",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n",
      "811\n",
      "56.59679408138101\n"
     ]
    }
   ],
   "source": [
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "offshore-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "494\n",
      "59.716599190283404\n"
     ]
    }
   ],
   "source": [
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "amended-screen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n",
      "494\n",
      "61.336032388663966\n"
     ]
    }
   ],
   "source": [
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "characteristic-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "94\n",
      "62.765957446808514\n"
     ]
    }
   ],
   "source": [
    "questions, answers, options = get_wbst_dataset(\"evaluation/mr.wbst.json\")\n",
    "model_judgments = get_model_judgments(questions, options)\n",
    "accuracy = 0\n",
    "for idx, ans in enumerate(answers):\n",
    "    if model_judgments[idx]==ans:\n",
    "        accuracy+=1\n",
    "print(accuracy*100/len(answers))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
