{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adequate-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize.indic_tokenize import trivial_tokenize\n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'mr'\n",
    "input_path = 'marathi_data/mr/mr.txt'\n",
    "output_path = 'marathi_data/mr/mr.tok.txt'\n",
    "\n",
    "normalizer_factory = IndicNormalizerFactory()\n",
    "normalizer = normalizer_factory.get_normalizer(lang)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confidential-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'hi'\n",
    "input_path = 'hindi_data/hindmonocorp05.plaintext'\n",
    "# input_path = 'hindi_data/hin.tok.txt'\n",
    "output_path = 'hindi_data/hin.tok2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considerable-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_factory = IndicNormalizerFactory()\n",
    "normalizer = normalizer_factory.get_normalizer(lang)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "animal-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenising Nepali\n",
    "\n",
    "input_data = list()\n",
    "data_file = open(\"nepali_data/nep_wikipedia_2021_100K/nep_wikipedia_2021_100K-sentences.txt\", \"r\")\n",
    "for line in data_file:\n",
    "#     print(line)\n",
    "    input_data.append(\" \".join(line.split()[2:]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powered-cartoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['रहेको थियो ।',\n",
       " 'टन देखि (१,८०,००० टन) को उत्पादन सगै यो फल मुल्य प्रति किलो ८०० देख १००० रुपिया सम्म पर्द्छ.',\n",
       " 'डेविड McDowall बताँदै अनुमानका साथ उच्चका रूपमा यस डाल, \"कुर्दहरुका आधुनिक इतिहास,\" आईबी Tauran, १९९६, ४४० स्नातकोत्तर र पूर्व मेयर Burhan Yengun भए भने कि यो रूपमा ६००.',\n",
       " \"सालको जनक्रान्तिको सम्झना गर्दा सबैभन्दा पहिले मेरो आँखामा 'लाले जोकर'का रूपमा प्रख्यात भएका तिनै चित्रकारको अनुहार मुस्कुराउँछ र हामी हिँडेको बाटोको सम्झना गराउँछ ।\",\n",
       " 'सालपछिको लोकतान्त्रिक आन्दोलनमा नेतृत्वदायी भूमिकामा रहेका कोइरालाले ६ वर्ष जेल र २० वर्ष प्रवास (भारत)मा बिताएका छन्।',\n",
       " 'सालमा प्रजातन्त्र आएपछि बजेट संसदसमक्ष प्रस्तुत गर्ने प्रणालीको विकास भएको हो ।',\n",
       " 'सालमा स्थापना भएको प्रहरीमा ११ औँ सङ्गठन प्रमुखको रूपमा ०३९ असारदेखि ०४३ जेठसम्म महानिरीक्षक बनेका लामाले आफ्नो कार्यकालमा सङ्गठनलाई आधुनिकीकरण र साधनस्रोत सम्पन्न बनाउन अग्रसरता देखाएका थिए ।',\n",
       " 'प्रतिशत) रहेका यी पहाडिया मुसलमानहरू पछिल्लो ई.स. २००१को जनगणनामा ४८९३ सङ्ख्या -०.',\n",
       " 'अमेरिकी डलरको मूल्यमा बिक्री भएको थियो।',\n",
       " 'किमी छ। यस सडक खण्डले सुर्खेतका मेलकुना,बोटेचौर,बजार हुदै सल्यान जिल्लाको सल्लीबजार,र सुर्खेत जिल्लाको सिम्ता जामुने बजार हुदै जाजरकोट पुगेको छ।']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-murray",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "selected-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authentic-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install epitran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "peripheral-modeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "mæːळiː\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ː'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import epitran\n",
    "epi = epitran.Epitran('hin-Deva')\n",
    "s = epi.transliterate(u'मैळी')\n",
    "print(len(s))\n",
    "print(s)\n",
    "s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "warming-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "favorite-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext.util\n",
    "# fasttext.util.download_model('hi', if_exists='ignore')  # English\n",
    "# ft = fasttext.load_model('cc.hi.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "ft = fasttext.load_model('cc.hi.300.bin')\n",
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.get_nearest_neighbors('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excellent-nancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 09:50:45 INFO: Loading these models for language: hi (Hindi):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | hdtb    |\n",
      "=======================\n",
      "\n",
      "2022-04-12 09:50:45 INFO: Use device: cpu\n",
      "2022-04-12 09:50:45 INFO: Loading: tokenize\n",
      "2022-04-12 09:50:45 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline('hi', processors='tokenize')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spatial-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stanza.download('hi', processors='tokenize' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aggressive-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['मैं', 'हु', 'ना।']\n"
     ]
    }
   ],
   "source": [
    "s = \"मैं हु ना।\"\n",
    "doc = nlp(s)\n",
    "print([word.text for sent in doc.sentences for word in sent.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empirical-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sent(sent):\n",
    "    normalized = normalizer.normalize(sent)\n",
    "    processed = ' '.join(trivial_tokenize(normalized, lang))\n",
    "    return processed\n",
    "\n",
    "def process_sent_stanza(sent):\n",
    "    doc = nlp(sent)\n",
    "    processed = [word.text for sent in doc.sentences for word in sent.tokens]\n",
    "    return \" \".join(processed)\n",
    "\n",
    "# with open(input_path, 'r', encoding='utf-8') as in_fp,\\\n",
    "# \t open(output_path, 'w', encoding='utf-8') as out_fp:\n",
    "#     for line in in_fp.readlines():\n",
    "#         sent = line.rstrip('\\n')\n",
    "#         toksent = process_sent(sent)\n",
    "#         out_fp.write(toksent)\n",
    "#         out_fp.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "quick-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open(\"nepali_data/nep_wikipedia_2021_100K/nep.tok.txt\", \"w\")\n",
    "for line in input_data:\n",
    "    new_line = process_sent(line)\n",
    "#     print(new_line)\n",
    "    output_file.write(new_line+\"\\n\")\n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "reduced-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "input_data = open(\"nepali_data/nep_wikipedia_2021_100K/nep.tok.EOLmarked.txt\", \"r\").read().split()\n",
    "word_set = Counter(input_data)\n",
    "output_file = open(\"nepali_data/nep_wikipedia_2021_100K/nep.tok.freqlist.txt\", \"w\")\n",
    "lexicon = sorted(word_set.items(), key = lambda x:x[1], reverse=True)\n",
    "for p in lexicon:\n",
    "    output_file.write(str(p[1])+\" \"+p[0]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "discrete-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streaming from gzip file\n",
    "import gzip\n",
    "    \n",
    "with open(input_path, \"r\") as in_fp, open(output_path, 'w', encoding='utf-8') as out_fp:\n",
    "    i=0\n",
    "    for line in in_fp:\n",
    "        \n",
    "#         if i<5:\n",
    "#             print(line.split(\"\\t\")[2])\n",
    "#             print(process_sent(line.split(\"\\t\")[2]))\n",
    "#             if i==5:\n",
    "#                 break\n",
    "        i+=1\n",
    "        if i<2000000:\n",
    "            continue\n",
    "        if i>=3000000:\n",
    "            break\n",
    "#         print(process_sent(str(line, \"utf8\").split(\"\\t\")[2].strip(\"\\n\")))\n",
    "        \n",
    "        out_fp.write(process_sent(line.split(\"\\t\")[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "    \n",
    "with open(input_path, \"r\") as in_fp, open(output_path, 'w', encoding='utf-8') as out_fp:\n",
    "    i=0\n",
    "    for line in in_fp:\n",
    "        \n",
    "#         if i<5:\n",
    "#             print(line.split(\"\\t\")[2])\n",
    "#             print(process_sent(line.split(\"\\t\")[2]))\n",
    "#             if i==5:\n",
    "#                 break\n",
    "        i+=1\n",
    "        if i<2000000:\n",
    "            continue\n",
    "        if i>=3000000:\n",
    "            break\n",
    "#         print(process_sent(str(line, \"utf8\").split(\"\\t\")[2].strip(\"\\n\")))\n",
    "        \n",
    "        out_fp.write(process_sent(line.split(\"\\t\")[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "humanitarian-geology",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9ef495808c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#         print(line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         print(process_sent(str(line, \"utf8\").split(\"\\t\")[2].strip(\"\\n\")))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_sent_stanza\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e2232ac20d8d>\u001b[0m in \u001b[0;36mprocess_sent_stanza\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_sent_stanza\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    251\u001b[0m         assert any([isinstance(doc, str), isinstance(doc, list),\n\u001b[1;32m    252\u001b[0m                     isinstance(doc, Document)]), 'input should be either str, list or Document'\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk_process\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbulk\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/stanza/pipeline/tokenize_processor.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, document)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# get dict data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         _, _, _, document = output_predictions(None, self.trainer, batches, self.vocab, None,\n\u001b[0m\u001b[1;32m     88\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_seqlen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenizeProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_SEQ_LENGTH_DEFAULT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                                                \u001b[0morig_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/stanza/models/tokenization/utils.py\u001b[0m in \u001b[0;36moutput_predictions\u001b[0;34m(output_file, trainer, data_generator, vocab, mwt_dict, max_seqlen, orig_text, no_ssplit, use_regex_tokens)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0meval_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchparas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/stanza/models/tokenization/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/stanza/models/tokenization/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, feats)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hierarchical'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hier_invtemp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0minp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoknoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtok0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hier_invtemp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0minp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from text file\n",
    "    \n",
    "with open(input_path, \"r\") as in_fp, open(output_path, 'w', encoding='utf-8') as out_fp:\n",
    "    i=0\n",
    "    for line in in_fp:\n",
    "        i+=1\n",
    "        if i%50000==0:\n",
    "            print(i)\n",
    "#             break\n",
    "#         print(line)\n",
    "#         print(process_sent(str(line, \"utf8\").split(\"\\t\")[2].strip(\"\\n\")))\n",
    "        out_fp.write(process_sent_stanza(line)+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-spokesman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-heading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-columbus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-lending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-automation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-light",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informal-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "स्वप्न दाखविणे आणि आश्वासने देणारे नेतेही लोकांना खूप आवडतात . \n",
      "\n",
      "['स', '्', 'वप', '्', 'न', 'द', 'ा', 'खव', 'ि', 'ण', 'े', 'आण', 'ि', 'आश', '्', 'व', 'ा', 'सन', 'े', 'द', 'े', 'ण', 'ा', 'र', 'े', 'न', 'े', 'त', 'े', 'ह', 'ी', 'ल', 'ो', 'क', 'ां', 'न', 'ा', 'ख', 'ू', 'प', 'आवडत', 'ा', 'त', '.']\n",
      "मुलांसोबतच पालकांना सांभाळण्याची जबाबदारी ही विवाहीत महिलांचीही आहे . . . केवळ , विवाह झालाय म्हणून वृद्ध पालकांची जबाबदारी त्यांना झटकता येणार नाही असं हायकोर्टानं म्हटलंय . \n",
      "\n",
      "['म', 'ु', 'ल', 'ां', 'स', 'ो', 'बतच', 'प', 'ा', 'लक', 'ां', 'न', 'ा', 'स', 'ां', 'भ', 'ा', 'ळण', '्', 'य', 'ा', 'च', 'ी', 'जब', 'ा', 'बद', 'ा', 'र', 'ी', 'ह', 'ी', 'व', 'ि', 'व', 'ा', 'ह', 'ी', 'त', 'मह', 'ि', 'ल', 'ां', 'च', 'ी', 'ह', 'ी', 'आह', 'े', '.', '.', '.', 'क', 'े', 'वळ', ',', 'व', 'ि', 'व', 'ा', 'ह', 'झ', 'ा', 'ल', 'ा', 'य', 'म', '्', 'हण', 'ू', 'न', 'व', 'ृ', 'द', '्', 'ध', 'प', 'ा', 'लक', 'ां', 'च', 'ी', 'जब', 'ा', 'बद', 'ा', 'र', 'ी', 'त', '्', 'य', 'ां', 'न', 'ा', 'झटकत', 'ा', 'य', 'े', 'ण', 'ा', 'र', 'न', 'ा', 'ह', 'ी', 'अस', 'ं', 'ह', 'ा', 'यक', 'ो', 'र', '्', 'ट', 'ा', 'न', 'ं', 'म', '्', 'हटल', 'ं', 'य', '.']\n",
      "पहा काय बरळला पाकड्यांचा पंतप्रधान इमरान खान\n",
      "\n",
      "['पह', 'ा', 'क', 'ा', 'य', 'बरळल', 'ा', 'प', 'ा', 'कड', '्', 'य', 'ां', 'च', 'ा', 'प', 'ं', 'तप', '्', 'रध', 'ा', 'न', 'इमर', 'ा', 'न', 'ख', 'ा', 'न']\n",
      "३ ( पीसीबी ) – मावळमध्ये पवना जलवाहिनीविरोधात आंदोलन करणाऱ्या आंदोलक शेतकऱ्यांवर गोळीबार करण्याचे आदेश मी दिल्याचा पंतप्रधान नरेंद्र मोदींचा आरोप चुकीचा आहे . \n",
      "\n",
      "['३', '(', 'प', 'ी', 'स', 'ी', 'ब', 'ी', ')', '–', 'म', 'ा', 'वळमध', '्', 'य', 'े', 'पवन', 'ा', 'जलव', 'ा', 'ह', 'ि', 'न', 'ी', 'व', 'ि', 'र', 'ो', 'ध', 'ा', 'त', 'आ', 'ं', 'द', 'ो', 'लन', 'करण', 'ा', 'र', '़्', 'य', 'ा', 'आ', 'ं', 'द', 'ो', 'लक', 'श', 'े', 'तकर', '़्', 'य', 'ां', 'वर', 'ग', 'ो', 'ळ', 'ी', 'ब', 'ा', 'र', 'करण', '्', 'य', 'ा', 'च', 'े', 'आद', 'े', 'श', 'म', 'ी', 'द', 'ि', 'ल', '्', 'य', 'ा', 'च', 'ा', 'प', 'ं', 'तप', '्', 'रध', 'ा', 'न', 'नर', 'ें', 'द', '्', 'र', 'म', 'ो', 'द', 'ीं', 'च', 'ा', 'आर', 'ो', 'प', 'च', 'ु', 'क', 'ी', 'च', 'ा', 'आह', 'े', '.']\n",
      "वृषभ : क्षुल्लक कारणाने तुम्ही अस्वस्थ व्हाल . \n",
      "\n",
      "['व', 'ृ', 'षभ', ':', 'क', '्', 'ष', 'ु', 'ल', '्', 'लक', 'क', 'ा', 'रण', 'ा', 'न', 'े', 'त', 'ु', 'म', '्', 'ह', 'ी', 'अस', '्', 'वस', '्', 'थ', 'व', '्', 'ह', 'ा', 'ल', '.']\n",
      "तो किती बद्दल , आम्ही नंतर तुम्हांला सांगतो . \n",
      "\n",
      "['त', 'ो', 'क', 'ि', 'त', 'ी', 'बद', '्', 'दल', ',', 'आम', '्', 'ह', 'ी', 'न', 'ं', 'तर', 'त', 'ु', 'म', '्', 'ह', 'ां', 'ल', 'ा', 'स', 'ां', 'गत', 'ो', '.']\n",
      "मुख्य पान चालू घडामोडी शेतकऱयांना कर्जमाफी किंवा भरपाई\n",
      "\n",
      "['म', 'ु', 'ख', '्', 'य', 'प', 'ा', 'न', 'च', 'ा', 'ल', 'ू', 'घड', 'ा', 'म', 'ो', 'ड', 'ी', 'श', 'े', 'तकर', '़', 'य', 'ां', 'न', 'ा', 'कर', '्', 'जम', 'ा', 'फ', 'ी', 'क', 'िं', 'व', 'ा', 'भरप', 'ा', 'ई']\n",
      "मुलांमध्ये भेदभाव पालकांनी करू नये , मिठाई आणली असेल तर सर्वाना द्यावी , फक्त एकाच मुलाला / मुलीला आणि इतरांना नाही असे नको . \n",
      "\n",
      "['म', 'ु', 'ल', 'ां', 'मध', '्', 'य', 'े', 'भ', 'े', 'दभ', 'ा', 'व', 'प', 'ा', 'लक', 'ां', 'न', 'ी', 'कर', 'ू', 'नय', 'े', ',', 'म', 'ि', 'ठ', 'ा', 'ई', 'आणल', 'ी', 'अस', 'े', 'ल', 'तर', 'सर', '्', 'व', 'ा', 'न', 'ा', 'द', '्', 'य', 'ा', 'व', 'ी', ',', 'फक', '्', 'त', 'एक', 'ा', 'च', 'म', 'ु', 'ल', 'ा', 'ल', 'ा', '/', 'म', 'ु', 'ल', 'ी', 'ल', 'ा', 'आण', 'ि', 'इतर', 'ां', 'न', 'ा', 'न', 'ा', 'ह', 'ी', 'अस', 'े', 'नक', 'ो', '.']\n",
      "राज्यातलं सरकार आणि मुख्यमंत्री चांगलं काम करत आहेत . \n",
      "\n",
      "['र', 'ा', 'ज', '्', 'य', 'ा', 'तल', 'ं', 'सरक', 'ा', 'र', 'आण', 'ि', 'म', 'ु', 'ख', '्', 'यम', 'ं', 'त', '्', 'र', 'ी', 'च', 'ां', 'गल', 'ं', 'क', 'ा', 'म', 'करत', 'आह', 'े', 'त', '.']\n",
      "चित्रपटातील गाणं रिमेक जरी असलं तरी त्यात बॉलिवूड स्टाईल वापरली असल्याने प्रेक्षकांना ते फार आवडत आहे . \n",
      "\n",
      "['च', 'ि', 'त', '्', 'रपट', 'ा', 'त', 'ी', 'ल', 'ग', 'ा', 'ण', 'ं', 'र', 'ि', 'म', 'े', 'क', 'जर', 'ी', 'असल', 'ं', 'तर', 'ी', 'त', '्', 'य', 'ा', 'त', 'ब', 'ॉ', 'ल', 'ि', 'व', 'ू', 'ड', 'स', '्', 'ट', 'ा', 'ईल', 'व', 'ा', 'परल', 'ी', 'असल', '्', 'य', 'ा', 'न', 'े', 'प', '्', 'र', 'े', 'क', '्', 'षक', 'ां', 'न', 'ा', 'त', 'े', 'फ', 'ा', 'र', 'आवडत', 'आह', 'े', '.']\n"
     ]
    }
   ],
   "source": [
    "from bpe import Encoder\n",
    "encoder = Encoder(100000, pct_bpe=0.2)  # params chosen for demonstration purposes\n",
    "encoder.fit(lines)\n",
    "for line in lines[:10]:\n",
    "    print(line)\n",
    "    print(encoder.tokenize(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intimate-progress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814674"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
